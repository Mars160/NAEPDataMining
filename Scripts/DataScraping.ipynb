{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDM Competition 2019-2020\n",
    "\n",
    "Objective: Scrape csv training data for meaningful insights\n",
    "Write CSV containing model grade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,datetime\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "#Scrape 1:\n",
    "# Time Spent on each Accession\n",
    "# Number of times each observable occurs\n",
    "# Total Time spent on question types\n",
    "# Number of questions completed\n",
    "# Number of total actions\n",
    "# Number of times revisiting a question\n",
    "############################################\n",
    "def scrape1(trainData, outCSV, labelData=None, hidden=False):\n",
    "    #initialize all tracking variables\n",
    "    curStudent = trainData.iloc[0,:]\n",
    "\n",
    "    startTime=endTime=qStart=qEnd = parseTime(curStudent['EventTime'])\n",
    "    actionCount = 0\n",
    "    curData = {'StudentID' : curStudent['STUDENTID']}\n",
    "    if(not hidden):\n",
    "        labelStudent = labelData.iloc[0,:]\n",
    "        curData['Target'] = labelStudent.loc['EfficientlyCompletedBlockB']\n",
    "    entryList = []\n",
    "    revisits = 0\n",
    "\n",
    "    questionCount = 0\n",
    "    studentCount = 0\n",
    "    rowCount= 0\n",
    "\n",
    "    for row in trainData.iterrows():\n",
    "        rowCount +=1\n",
    "        if(rowCount % 100000 == 0):\n",
    "            print(rowCount)\n",
    "        actionCount +=1\n",
    "\n",
    "\n",
    "        #print(rowCount)\n",
    "        #break between students - Write to row\n",
    "        if((row[1].loc['STUDENTID'] != curStudent.loc['STUDENTID'])) or row[0] == len(trainData)-1:\n",
    "            curData['NumActs'] = actionCount\n",
    "            curData['NumQuests'] = questionCount\n",
    "            curData['Revisits'] = revisits\n",
    "            entryList.append(curData)\n",
    "            studentCount+=1\n",
    "\n",
    "            #update tracking vars for next student if not last student\n",
    "            if(row[0] != len(trainData)-1): \n",
    "                curStudent = row[1]\n",
    "                curData = {'StudentID' : curStudent['STUDENTID']}\n",
    "                if(not hidden):\n",
    "                    labelStudent = labelData.iloc[studentCount,:]\n",
    "                    curData['Target'] = labelStudent.loc['EfficientlyCompletedBlockB']\n",
    "\n",
    "            startTime=endTime=qStart=qEnd = parseTime(row[1].loc['EventTime'])\n",
    "            actionCount=0\n",
    "            revisits = 0\n",
    "            questionCount=0\n",
    "\n",
    "        #break between questions\n",
    "        elif(row[1].loc['AccessionNumber'] != trainData.iloc[row[0]-1,:].loc['AccessionNumber']):\n",
    "\n",
    "            #if we have NOT seen this question before\n",
    "            if(row[1].loc['AccessionNumber'] not in curData.keys()):\n",
    "                questionCount +=1\n",
    "                curData[row[1].loc['AccessionNumber']] = (qEnd-qStart).total_seconds()\n",
    "            else:\n",
    "                revisits +=1\n",
    "                curData[row[1].loc['AccessionNumber']] += (qEnd-qStart).total_seconds()\n",
    "\n",
    "            if(row[1].loc['ItemType'] not in curData.keys()):\n",
    "                curData[row[1].loc['ItemType']] = (qEnd - qStart).total_seconds()\n",
    "            else:\n",
    "                curData[row[1].loc['ItemType']] += (qEnd-qStart).total_seconds()\n",
    "\n",
    "            #update the starting time for a new question\n",
    "            if(str(row[1].loc['EventTime']) != 'nan'): qStart=qEnd=parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "         #update the ending time with each row\n",
    "        if(str(row[1].loc['EventTime']) != 'nan'): endTime=qEnd=parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "        #Add new observable\n",
    "        if(row[1].loc['Observable'] not in curData.keys()): curData[row[1].loc['Observable']] =1\n",
    "\n",
    "        #Add to the count of this observable\n",
    "        else: curData[row[1].loc['Observable']] +=1\n",
    "\n",
    "    outData = pd.DataFrame(entryList)\n",
    "    outData.to_csv(outCSV,index=False)\n",
    "    \n",
    "#Scrape2\n",
    "#Process Scrape\n",
    "# For each process:\n",
    "#    Number of times the process occurred\n",
    "#    Total time spent on this process\n",
    "#    Average time spent on this process\n",
    "############################################\n",
    "def scrape2(trainData, procList, outCSV):\n",
    "    dataList = []\n",
    "    for row in trainData.itertuples():\n",
    "        #break between students\n",
    "        dataList.append([row.STUDENTID, row.Observable,row.EventTime])\n",
    "\n",
    "    curID = dataList[0][0]\n",
    "    count = 0\n",
    "    curActions = []\n",
    "    studentList =[]\n",
    "    finalList = []\n",
    "    for i in dataList:\n",
    "        #add all actions for current student to curActions\n",
    "        if(curID == i[0]):\n",
    "            curActions.append(i)\n",
    "        #break between students\n",
    "        else:\n",
    "            studentList.append([curID,curActions])\n",
    "            curActions = []\n",
    "            curID = i[0]\n",
    "    studentList.append([curID,curActions])\n",
    "\n",
    "    i = j = 0\n",
    "    while(i<len(studentList)):\n",
    "        commonProcs = {}\n",
    "        #print(i)\n",
    "        j=0\n",
    "        while(j<len(procList)):\n",
    "            commonProcs = compareProcs2(commonProcs,studentList[i][1],procList[j])\n",
    "            j+=1\n",
    "        commonProcs['StudentID'] = studentList[i][0]\n",
    "        finalList.append(commonProcs)\n",
    "        i+=1\n",
    "    outData = pd.DataFrame(finalList)\n",
    "    outData.to_csv(outCSV,index=False)\n",
    "    \n",
    "\n",
    "#scrape3\n",
    "# Starting Time\n",
    "# Time spent on each observable\n",
    "# ActionRate - amount of time taken every 10 clicks\n",
    "############################################\n",
    "def scrape3(trainData, outCSV, labelData=None):\n",
    "    #initialize all tracking variables\n",
    "    curStudent = trainData.iloc[0,:]\n",
    "    #labelStudent = labelData.iloc[0,:]\n",
    "    actionTimerEnd=actionTimer=startTime=endTime=qStart=qEnd = parseTime(curStudent['EventTime'])\n",
    "    #nonQuestions = ['Directions','BlockReview','TimeLeftMessage','Help']\n",
    "    actionCount = 0\n",
    "    obsTimer = 0\n",
    "    reviewTime = 0\n",
    "    curData = {'StudentID' : curStudent['STUDENTID'], 'StartTime':parseTime(curStudent['EventTime']).total_seconds()}\n",
    "    entryList = []\n",
    "\n",
    "    questionCount = 0\n",
    "    studentCount = 0\n",
    "    rowCount= 0\n",
    "    priorObs = startTime\n",
    "\n",
    "    for row in trainData.iterrows():\n",
    "        rowCount +=1\n",
    "        if(rowCount % 100000 == 0):\n",
    "            print(rowCount)\n",
    "        actionCount +=1\n",
    "\n",
    "        observed = row[1].loc['Observable']\n",
    "\n",
    "\n",
    "        #print(rowCount)\n",
    "        #break between students - Write to row\n",
    "        if((row[1].loc['STUDENTID'] != curStudent.loc['STUDENTID'])) or row[0] == len(trainData)-1:\n",
    "            entryList.append(curData)\n",
    "            studentCount+=1\n",
    "\n",
    "            #update tracking vars for next student if not last student\n",
    "            if(row[0] != len(trainData)-1): curStudent = row[1]\n",
    "            actionTimer=startTime=endTime=qStart=qEnd = parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "            curData = {'StudentID' : curStudent['STUDENTID']}\n",
    "            curData['StartTime'] = parseTime(row[1].loc['EventTime']).total_seconds()\n",
    "            actionCount=0\n",
    "            priorObs = startTime\n",
    "            questionCount=0\n",
    "            reviewTime = 0\n",
    "\n",
    "        #break between questions\n",
    "        elif(row[1].loc['AccessionNumber'] != trainData.iloc[row[0]-1,:].loc['AccessionNumber']):\n",
    "\n",
    "            #update the starting time for a new question\n",
    "            if(str(row[1].loc['EventTime']) != 'nan'): qStart=qEnd=parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "         #update the ending time with each row\n",
    "        if(str(row[1].loc['EventTime']) != 'nan'): endTime=qEnd=actionTimerEnd=obsTimer=parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "        #Add new observable\n",
    "        if(row[1].loc['Observable']+\"_T\" not in curData.keys()):\n",
    "            curData[row[1].loc['Observable']+\"_T\"] = (obsTimer-priorObs).total_seconds()\n",
    "\n",
    "        #Add to the count of this observable\n",
    "        else:\n",
    "            curData[row[1].loc['Observable']+\"_T\"] += (obsTimer-priorObs).total_seconds()\n",
    "\n",
    "        #add time for last 10 actions\n",
    "        if(actionCount%10 == 0 and actionCount<600):\n",
    "            curData[\"actionRate\" +str(actionCount)] = (actionTimerEnd-actionTimer).total_seconds()\n",
    "            actionTimer=actionTimerEnd=parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "        priorObs =obsTimer\n",
    "\n",
    "    outData = pd.DataFrame(entryList)\n",
    "    outData.to_csv(outCSV,index=False)\n",
    "\n",
    "#scrape4\n",
    "# Click Rate - Number of clicks taken per minute every minute\n",
    "############################################\n",
    "def scrape4(trainData, outCSV):\n",
    "    #initialize all tracking variables\n",
    "    curStudent = trainData.iloc[0,:]\n",
    "    #labelStudent = labelData.iloc[0,:]\n",
    "    actionTimerEnd=actionTimer=startTime=endTime=qStart=qEnd = parseTime(curStudent['EventTime'])\n",
    "    #nonQuestions = ['Directions','BlockReview','TimeLeftMessage','Help']\n",
    "    actionCount = 0\n",
    "    actionMark = 0\n",
    "    obsTimer = 0\n",
    "    reviewTime = 0\n",
    "    curData = {'StudentID' : curStudent['STUDENTID']}\n",
    "    entryList = []\n",
    "\n",
    "    questionCount = 0\n",
    "    studentCount = 0\n",
    "    rowCount= 0\n",
    "    priorObs = startTime\n",
    "\n",
    "    for row in trainData.iterrows():\n",
    "        rowCount +=1\n",
    "        if(rowCount % 100000 == 0):\n",
    "            print(rowCount)\n",
    "        actionCount +=1\n",
    "\n",
    "        observed = row[1].loc['Observable']\n",
    "\n",
    "\n",
    "        #print(rowCount)\n",
    "        #break between students - Write to row\n",
    "        if((row[1].loc['STUDENTID'] != curStudent.loc['STUDENTID'])) or row[0] == len(trainData)-1:\n",
    "            entryList.append(curData)\n",
    "            studentCount+=1\n",
    "\n",
    "            #update tracking vars for next student if not last student\n",
    "            if(row[0] != len(trainData)-1): curStudent = row[1]\n",
    "            actionTimer=startTime=actionTimerEnd = parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "            curData = {'StudentID' : curStudent['STUDENTID']}\n",
    "            actionCount=0\n",
    "            actionMark = 0\n",
    "\n",
    "\n",
    "         #update the ending time with each row\n",
    "        if(str(row[1].loc['EventTime']) != 'nan'): endTime=qEnd=actionTimerEnd=obsTimer=parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "        #add time for last 10 actions\n",
    "        if((actionTimerEnd - actionTimer).total_seconds()>60):\n",
    "            curData[\"clickRate\" +str(actionMark)] = actionCount\n",
    "            actionTimer=actionTimerEnd=parseTime(row[1].loc['EventTime'])\n",
    "            actionMark +=1\n",
    "            actionCount = 0\n",
    "\n",
    "        priorObs =obsTimer\n",
    "\n",
    "    outData = pd.DataFrame(entryList)\n",
    "    outData.to_csv(outCSV,index=False)\n",
    "\n",
    "#scrape5\n",
    "# Clicks per accession type\n",
    "# Clicks per question\n",
    "############################################\n",
    "def scrape5(trainData, outCSV):\n",
    "    #initialize all tracking variables\n",
    "    curStudent = trainData.iloc[0,:]\n",
    "    actionCount = 0\n",
    "\n",
    "    obsTimer = 0\n",
    "    reviewTime = 0\n",
    "    curData = {'StudentID' : curStudent['STUDENTID']}\n",
    "    entryList = []\n",
    "\n",
    "    rowCount= 0\n",
    "\n",
    "    for row in trainData.iterrows():\n",
    "        rowCount +=1\n",
    "        if(rowCount % 100000 == 0):\n",
    "            print(rowCount)\n",
    "        actionCount +=1\n",
    "\n",
    "        observed = row[1].loc['Observable']\n",
    "\n",
    "\n",
    "        #print(rowCount)\n",
    "        #break between students - Write to row\n",
    "        if((row[1].loc['STUDENTID'] != curStudent.loc['STUDENTID'])) or row[0] == len(trainData)-1:\n",
    "            entryList.append(curData)\n",
    "\n",
    "            #update tracking vars for next student if not last student\n",
    "            if(row[0] != len(trainData)-1): curStudent = row[1]\n",
    "            actionTimer=startTime=actionTimerEnd = parseTime(row[1].loc['EventTime'])\n",
    "\n",
    "            curData = {'StudentID' : curStudent['STUDENTID']}\n",
    "\n",
    "        # Add new ItemType\n",
    "        if (row[1].loc['ItemType']+\"ObsClicks\" not in curData.keys()):\n",
    "            curData[row[1].loc['ItemType']+\"ObsClicks\"] = 1\n",
    "\n",
    "            # Add to the count of this observable\n",
    "        else:\n",
    "            curData[row[1].loc['ItemType']+\"ObsClicks\"] += 1\n",
    "\n",
    "        # Add new Question\n",
    "        if (row[1].loc['AccessionNumber']+\"QClicks\" not in curData.keys()):\n",
    "            curData[row[1].loc['AccessionNumber']+\"QClicks\"] = 1\n",
    "\n",
    "            # Add to the count of this observable\n",
    "        else:\n",
    "            curData[row[1].loc['AccessionNumber']+\"QClicks\"] += 1\n",
    "\n",
    "\n",
    "    outData = pd.DataFrame(entryList)\n",
    "    outData.to_csv(outCSV,index=False)\n",
    "    \n",
    "#addStats\n",
    "\n",
    "def addStats(featureData, outCSV):\n",
    "    data = pd.read_csv(featureData)\n",
    "    \n",
    "    #stats for average process times\n",
    "    pt_r_Col = [col for col in data if (col.endswith('_PT_R'))]\n",
    "    pt_r_DF = data[pt_r_Col]\n",
    "\n",
    "    rowList = []\n",
    "\n",
    "    for row in pt_r_DF.iterrows():\n",
    "        rowDict = {}\n",
    "        description = row[1].describe()\n",
    "        rowDict['mean_PT_R'] = description['mean']\n",
    "        rowDict['sd_PT_R'] = description['std']\n",
    "        rowDict['max_PT_R'] = description['max']\n",
    "        rowDict['min_PT_R'] = description['min']\n",
    "        rowDict['range_PT_R'] = description['max'] - description['min']\n",
    "        rowList.append(rowDict)\n",
    "\n",
    "    df = pd.DataFrame(rowList)\n",
    "    data = pd.concat([data,df], axis=1)\n",
    "    \n",
    "    #stats for total process times\n",
    "    pt_Col = [col for col in data if (col.endswith('_PT'))]\n",
    "    pt_DF = data[pt_Col]\n",
    "    \n",
    "    rowList = []\n",
    "\n",
    "    for row in pt_DF.iterrows():\n",
    "        rowDict = {}\n",
    "        description = row[1].describe()\n",
    "        rowDict['mean_PT'] = description['mean']\n",
    "        rowDict['sd_PT'] = description['std']\n",
    "        rowDict['max_PT'] = description['max']\n",
    "        rowDict['min_PT'] = description['min']\n",
    "        rowDict['range_PT'] = description['max'] - description['min']\n",
    "        rowList.append(rowDict)\n",
    "\n",
    "    df = pd.DataFrame(rowList)\n",
    "    data = pd.concat([data,df], axis=1)\n",
    "    \n",
    "    #stats for action rate\n",
    "    \n",
    "    actionCol = [col for col in data if col.startswith('actionRate')]\n",
    "    actionDF = data[actionCol]\n",
    "\n",
    "    rowList = []\n",
    "\n",
    "    for row in actionDF.iterrows():\n",
    "        rowDict = {}\n",
    "        description = row[1].describe()\n",
    "        rowDict['meanAction'] = description['mean']\n",
    "        rowDict['sdAction'] = description['std']\n",
    "        rowDict['maxAction'] = description['max']\n",
    "        rowDict['minAction'] = description['min']\n",
    "        rowDict['rangeAction'] = description['max'] - description['min']\n",
    "        rowList.append(rowDict)\n",
    "\n",
    "    df = pd.DataFrame(rowList)\n",
    "    data = pd.concat([data,df], axis=1)\n",
    "    \n",
    "    #stats for click rate\n",
    "\n",
    "    cr_Col = [col for col in data if col.startswith('clickRate')]\n",
    "    cr_DF = data[cr_Col]\n",
    "\n",
    "    rowList = []\n",
    "\n",
    "    for row in cr_DF.iterrows():\n",
    "        rowDict = {}\n",
    "        description = row[1].describe()\n",
    "        rowDict['meanCR'] = description['mean']\n",
    "        rowDict['sdCR'] = description['std']\n",
    "        rowDict['maxCR'] = description['max']\n",
    "        rowDict['minCR'] = description['min']\n",
    "        rowDict['rangeCR'] = description['max'] - description['min']\n",
    "        rowList.append(rowDict)\n",
    "\n",
    "    df = pd.DataFrame(rowList)\n",
    "    data = pd.concat([data,df], axis=1)\n",
    "\n",
    "    #stats for question times\n",
    "    questionCol = [col for col in data if (col.startswith('VH') and not col.endswith('Clicks'))]\n",
    "    questionsDF = data[questionCol]\n",
    "    questionsDF.head()\n",
    "\n",
    "    rowList = []\n",
    "\n",
    "    for row in questionsDF.iterrows():\n",
    "        rowDict = {}\n",
    "        description = row[1].describe()\n",
    "        rowDict['meanQ'] = description['mean']\n",
    "        rowDict['sdQ'] = description['std']\n",
    "        rowDict['maxQ'] = description['max']\n",
    "        rowDict['minQ'] = description['min']\n",
    "        rowDict['rangeQ'] = description['max'] - description['min']\n",
    "        rowList.append(rowDict)\n",
    "\n",
    "    df = pd.DataFrame(rowList)\n",
    "    data = pd.concat([data,df], axis=1)\n",
    "\n",
    "    #stats for question clicks\n",
    "    questionCol = [col for col in data if (col.startswith('VH') and col.endswith('Clicks'))]\n",
    "    questionsDF = data[questionCol]\n",
    "    questionsDF.head()\n",
    "\n",
    "    rowList = []\n",
    "\n",
    "    for row in questionsDF.iterrows():\n",
    "        rowDict = {}\n",
    "        description = row[1].describe()\n",
    "        rowDict['meanQClicks'] = description['mean']\n",
    "        rowDict['sdQClicks'] = description['std']\n",
    "        rowDict['maxQClicks'] = description['max']\n",
    "        rowDict['minQClicks'] = description['min']\n",
    "        rowDict['rangeQClicks'] = description['max'] - description['min']\n",
    "        rowList.append(rowDict)\n",
    "\n",
    "    df = pd.DataFrame(rowList)\n",
    "    data = pd.concat([data,df], axis=1)\n",
    "\n",
    "    #stats for observation clicks\n",
    "    questionCol = [col for col in data if col.endswith('ObsClicks')]\n",
    "    questionsDF = data[questionCol]\n",
    "    questionsDF.head()\n",
    "\n",
    "    rowList = []\n",
    "\n",
    "    for row in questionsDF.iterrows():\n",
    "        rowDict = {}\n",
    "        description = row[1].describe()\n",
    "        rowDict['meanObsClicks'] = description['mean']\n",
    "        rowDict['sdObsClicks'] = description['std']\n",
    "        rowDict['maxObsClicks'] = description['max']\n",
    "        rowDict['minObsClicks'] = description['min']\n",
    "        rowDict['rangeObsClicks'] = description['max'] - description['min']\n",
    "        rowList.append(rowDict)\n",
    "\n",
    "    df = pd.DataFrame(rowList)\n",
    "    data = pd.concat([data,df], axis=1)\n",
    "    \n",
    "    data.to_csv(outCSV, index=False)\n",
    "    \n",
    "#convert time stamp into timeDelta object for arithmetic operations\n",
    "def parseTime(eventTime):\n",
    "    timeString = eventTime.split()[1].split(':')\n",
    "    t = datetime.timedelta(hours=int(timeString[0]), minutes=int(timeString[1]), seconds=int(timeString[2].split('.')[0]), milliseconds=int(timeString[2].split('.')[1]))\n",
    "    return t\n",
    "\n",
    "\n",
    "#truncate the training data by time into segments\n",
    "#write truncated data to cutCSV\n",
    "############################################\n",
    "def timeCut(trainData, cutTime, cutCSV, outData=None):\n",
    "    outData = pd.DataFrame(columns=['STUDENTID','Block','AccessionNumber','ItemType','Observable','ExtendedInfo','EventTime'])\n",
    "    dataList = []\n",
    "    curStudent = trainData.iloc[0,:]\n",
    "    firstStudent = trainData.iloc[0,:]\n",
    "    startTime = parseTime(firstStudent['EventTime'])\n",
    "    endTime = parseTime(firstStudent['EventTime'])\n",
    "    rowNum = 0\n",
    "    for row in trainData.iterrows():\n",
    "        rowNum += 1\n",
    "        if ((row[1].loc['STUDENTID'] != curStudent.loc['STUDENTID'])):\n",
    "            curStudent = row[1]\n",
    "            startTime = parseTime(row[1].loc['EventTime'])\n",
    "            endTime = startTime\n",
    "        if (str(row[1].loc['EventTime']) != 'nan'):\n",
    "            endTime = parseTime(row[1].loc['EventTime'])\n",
    "            if((endTime-startTime).total_seconds()<cutTime):\n",
    "                dataList.append(row[1])\n",
    "\n",
    "    outData = pd.DataFrame(dataList,columns=['STUDENTID','Block','AccessionNumber','ItemType','Observable','ExtendedInfo','EventTime'])\n",
    "    outData.to_csv(cutCSV,index=False)\n",
    "\n",
    "\n",
    "#Used to split into True and False datasets for process mining using Fluxicon Disco\n",
    "############################################\n",
    "def tFSplit(trainData, labelData, trueCSV, falseCSV):\n",
    "    curStudent = labelData.iloc[0, :]\n",
    "    studentCount = 0\n",
    "    falseList = []\n",
    "    trueList = []\n",
    "    rowCount = 0\n",
    "\n",
    "    for row in trainData.iterrows():\n",
    "        rowCount += 1\n",
    "        if (rowCount % 100000 == 0):\n",
    "            print(rowCount)\n",
    "        # print(rowCount)\n",
    "        if((row[1].loc['STUDENTID'] != curStudent.loc['STUDENTID'])) or row[0] == len(trainData)-1:\n",
    "            studentCount += 1\n",
    "            if (row[0] != len(trainData) - 1): curStudent = labelData.iloc[studentCount, :]\n",
    "\n",
    "        curDict = row[1].to_dict()\n",
    "        if(curStudent.loc['Target'] == True):\n",
    "            curDict['Target'] = True\n",
    "            trueList.append(curDict)\n",
    "        else:\n",
    "            curDict['Target'] = False\n",
    "            falseList.append(curDict)\n",
    "\n",
    "    trueData = pd.DataFrame(trueList)\n",
    "    falseData = pd.DataFrame(falseList)\n",
    "    trueData.to_csv(trueCSV, index=False)\n",
    "    falseData.to_csv(falseCSV, index=False)\n",
    "\n",
    "def concatAllScrapes(label, outCSV):\n",
    "    path = '../TrainingData/'\n",
    "    print(path+'scrape1_'+label)\n",
    "    scrape1 = pd.read_csv(path+'scrape1_'+label+'.csv')\n",
    "    scrape2 = pd.read_csv(path+'scrape2_'+label+'.csv')\n",
    "    scrape3 = pd.read_csv(path+'scrape3_'+label+'.csv')\n",
    "    scrape4 = pd.read_csv(path+'scrape4_'+label+'.csv')\n",
    "    scrape5 = pd.read_csv(path+'scrape5_'+label+'.csv')\n",
    "    scrape2 = scrape2.drop(\"StudentID\", axis=1)\n",
    "    scrape3 = scrape3.drop(\"StudentID\", axis=1)\n",
    "    scrape4 = scrape4.drop(\"StudentID\", axis=1)\n",
    "    scrape5 = scrape5.drop(\"StudentID\", axis=1)\n",
    "    allScrapes=pd.concat([scrape1,scrape2,scrape3,scrape4,scrape5],axis=1)\n",
    "    allScrapes.to_csv(path+outCSV, index=False)\n",
    "    \n",
    "\n",
    "#Common processes - generated from Fluxicon Disco process maps\n",
    "procs = [\"Draw;Scratchwork Erase Mode On;Erase\",\n",
    "         \"Scratchwork Mode Off;Vertical Item Scroll;Eliminate Choice\",\n",
    "         \"Close Calculator;Open Calculator\",\n",
    "         \"Lose Focus;Click Progress Navigator\",\n",
    "         \"Receive Focus;Equation Editor Button\",\n",
    "         \"Vertical Item Scroll;Lose Focus\",\n",
    "         \"Vertical Item Scroll;Open Calculator;Click Choice\",\n",
    "         \"Enter Item;Open Calculator\",\n",
    "         \"Enter Item;Click Choice\",\n",
    "         \"Enter Item;Receive Focus\",\n",
    "         \"Enter Item;Eliminate Choice\",\n",
    "         \"Enter Item;Next\",\n",
    "         \"Enter Item;Vertical Item Scroll;Open Calculator\",\n",
    "         \"Enter Item;Open Calculator;Calculator Buffer\",\n",
    "         \"Enter Item;DropChoice\",\n",
    "         \"Enter Item;Scratchwork Mode On\",\n",
    "         \"Enter Item;Click Progress Navigator\",\n",
    "         \"Enter Item;Increase Zoom\",\n",
    "         \"Move Calculator;Exit Item\",\n",
    "         \"Move Calculator;DropChoice\",\n",
    "         \"Move Calculator;Receive Focus\",\n",
    "         \"Move Calculator;Click Choice\",\n",
    "         \"Open Calculator;Click Choice\",\n",
    "         \"Close Calculator;Open Calculator\",\n",
    "         \"Receive Focus;Lose Focus\",\n",
    "         \"Vertical Item Scroll;Open Calculator\",\n",
    "         \"Exit Item;Enter Item;Click Choice\",\n",
    "         \"Exit Item;Enter Item\",\n",
    "         \"Exit Item;Enter Item;Next\",\n",
    "         \"Math Keypress;First Text Change\",\n",
    "         \"Draw;Draw\",\"Enter Item;Next;Exit Item\",\n",
    "        \"Exit Item;Calculator Buffer;Close Calculator;Click Choice\",\n",
    "        \"Close Calculator;Click Choice\",\n",
    "        \"Exit Item;Calculator Buffer\",\n",
    "        \"Enter Item;Open Calculator;Move Calculator;DropChoice\",\n",
    "        \"Enter Item;Open Calculator;Move Calculator\",\n",
    "        \"Click Choice;Next;Exit Item\",\n",
    "        \"Click Choice;Next\",\n",
    "        \"Enter Item;Eliminate Choice;Click Choice\",\n",
    "        \"Vertical Item Scroll;Next\",\n",
    "        \"Move Calculator;Eliminate Choice\",\n",
    "        \"Click Choice;Click Progress Navigator\",\n",
    "        \"Click Progress Navigator;Exit Item\",\n",
    "        \"DropChoice;DropChoice\",\n",
    "        \"Calculator Buffer;Enter Item\",\n",
    "        \"Move Calculator;Move Calculator\",\n",
    "        \"Clear Answer;Click Choice\",\n",
    "        \"Exit Item;Calculator Buffer;Close Calculator\",\n",
    "        \"Receive Focus;Math Keypress;Lose Focus\",\n",
    "        \"Receive Focus;Math Keypress\",\n",
    "        \"Draw;Clear Scratchwork\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the training data and split it into 10, 20, and 30 minute data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TrainingData/data_a_train.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    timeCut(dataReader, 600, '../TrainingData/data_a_train_10.csv')\n",
    "    timeCut(dataReader, 1200, '../TrainingData/data_a_train_20.csv')\n",
    "    timeCut(dataReader, 1800, '../TrainingData/data_a_train_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TrainingData/data_a_train_10.csv', newline='') as dataFile:\n",
    "    with open('../TrainingData/data_train_label.csv', newline='') as labelFile:\n",
    "        dataReader = pd.read_csv(dataFile)\n",
    "        labelReader = pd.read_csv(labelFile)\n",
    "        scrape1(dataReader, '../TrainingData/scrape1_T10.csv', labelReader)\n",
    "        \n",
    "with open('../TrainingData/data_a_train_20.csv', newline='') as dataFile:\n",
    "    with open('../TrainingData/data_train_label.csv', newline='') as labelFile:\n",
    "        dataReader = pd.read_csv(dataFile)\n",
    "        labelReader = pd.read_csv(labelFile)\n",
    "        scrape1(dataReader, '../TrainingData/scrape1_T20.csv', labelReader)\n",
    "        \n",
    "with open('../TrainingData/data_a_train_30.csv', newline='') as dataFile:\n",
    "    with open('../TrainingData/data_train_label.csv', newline='') as labelFile:\n",
    "        dataReader = pd.read_csv(dataFile)\n",
    "        labelReader = pd.read_csv(labelFile)\n",
    "        scrape1(dataReader, '../TrainingData/scrape1_T30.csv', labelReader)\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_10.csv', newline='') as dataFile:\n",
    "    with open('../TrainingData/data_train_label.csv', newline='') as labelFile:\n",
    "        dataReader = pd.read_csv(dataFile)\n",
    "        labelReader = pd.read_csv(labelFile)\n",
    "        scrape1(dataReader, '../TrainingData/scrape1_H10.csv', labelReader, True)\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_20.csv', newline='') as dataFile:\n",
    "    with open('../TrainingData/data_train_label.csv', newline='') as labelFile:\n",
    "        dataReader = pd.read_csv(dataFile)\n",
    "        labelReader = pd.read_csv(labelFile)\n",
    "        scrape1(dataReader, '../TrainingData/scrape1_H20.csv', labelReader, True)\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_30.csv', newline='') as dataFile:\n",
    "    with open('../TrainingData/data_train_label.csv', newline='') as labelFile:\n",
    "        dataReader = pd.read_csv(dataFile)\n",
    "        scrape1(dataReader, '../TrainingData/scrape1_H30.csv', labelReader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TrainingData/data_a_train_10.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape2(dataReader,procs, '../TrainingData/scrape2_T10.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_train_20.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape2(dataReader,procs, '../TrainingData/scrape2_T20.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_train_30.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape2(dataReader,procs, '../TrainingData/scrape2_T30.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_10.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape2(dataReader,procs, '../TrainingData/scrape2_H10.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_20.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape2(dataReader,procs, '../TrainingData/scrape2_H20.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_30.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape2(dataReader,procs, '../TrainingData/scrape2_H30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TrainingData/data_a_train_10.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape3(dataReader, '../TrainingData/scrape3_T10.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_train_20.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape3(dataReader, '../TrainingData/scrape3_T20.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_train_30.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape3(dataReader, '../TrainingData/scrape3_T30.csv')\n",
    "\n",
    "with open('../TrainingData/data_a_hidden_10.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape3(dataReader, '../TrainingData/scrape3_H10.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_20.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape3(dataReader, '../TrainingData/scrape3_H20.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_30.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape3(dataReader, '../TrainingData/scrape3_H30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TrainingData/data_a_train_10.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape4(dataReader, '../TrainingData/scrape4_T10.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_train_20.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape4(dataReader, '../TrainingData/scrape4_T20.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_train_30.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape4(dataReader, '../TrainingData/scrape4_T30.csv')\n",
    "\n",
    "with open('../TrainingData/data_a_hidden_10.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape4(dataReader, '../TrainingData/scrape4_H10.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_20.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape4(dataReader, '../TrainingData/scrape4_H20.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_30.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape4(dataReader, '../TrainingData/scrape4_H30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TrainingData/data_a_train_10.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape5(dataReader, '../TrainingData/scrape5_T10.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_train_20.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape5(dataReader, '../TrainingData/scrape5_T20.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_train_30.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape5(dataReader, '../TrainingData/scrape5_T30.csv')\n",
    "\n",
    "with open('../TrainingData/data_a_hidden_10.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape5(dataReader, '../TrainingData/scrape5_H10.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_20.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape5(dataReader, '../TrainingData/scrape5_H20.csv')\n",
    "        \n",
    "with open('../TrainingData/data_a_hidden_30.csv', newline='') as dataFile:\n",
    "    dataReader = pd.read_csv(dataFile)\n",
    "    scrape5(dataReader, '../TrainingData/scrape5_H30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatAllScrapes('T10','FullScrapeT10.csv')\n",
    "concatAllScrapes('T20','FullScrapeT20.csv')\n",
    "concatAllScrapes('T30','FullScrapeT30.csv')\n",
    "concatAllScrapes('H10','FullScrapeH10.csv')\n",
    "concatAllScrapes('H20','FullScrapeH20.csv')\n",
    "concatAllScrapes('H30','FullScrapeH30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addStats('../TrainingData/FullScrapeT10.csv', '../TrainingData/FullScrapeT10.csv')\n",
    "addStats('../TrainingData/FullScrapeT20.csv', '../TrainingData/FullScrapeT20.csv')\n",
    "addStats('../TrainingData/FullScrapeT30.csv', '../TrainingData/FullScrapeT30.csv')\n",
    "addStats('../TrainingData/FullScrapeH10.csv', '../TrainingData/FullScrapeH10.csv')\n",
    "addStats('../TrainingData/FullScrapeH20.csv', '../TrainingData/FullScrapeH20.csv')\n",
    "addStats('../TrainingData/FullScrapeH30.csv', '../TrainingData/FullScrapeH30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "authors": [
    {
     "name": "Nathan Levin"
    }
   ],
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
