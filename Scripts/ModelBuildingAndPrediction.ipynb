{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv, datetime\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import fastai as fast\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Performing grid search\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Scoring Function Based on combined adjusted AUC and adjusted Kappa\n",
    "def scoreFunc(y_test, preds):\n",
    "    rocAUC = roc_auc_score(y_test, preds)\n",
    "    print('AUC: ' + str(rocAUC))\n",
    "    roundedPreds = preds.round()\n",
    "    Kappa = cohen_kappa_score(y_test,roundedPreds)\n",
    "    AdjAUC = (rocAUC - 0.5) * 2 if (rocAUC>0.5) else 0\n",
    "    print('AdjustedAUC: ' + str(AdjAUC))\n",
    "    AdjKappa = Kappa if (Kappa > 0) else 0\n",
    "    print('Kappa: ' + str(Kappa))\n",
    "    print('AdjustedKappa: ' + str(AdjKappa))\n",
    "    return AdjAUC + AdjKappa\n",
    "\n",
    "#Scoring Function Based on combined adjusted AUC and adjusted Kappa\n",
    "def evalFunc(preds, y_test):\n",
    "    y_labels = y_test.get_label()\n",
    "    rocAUC = roc_auc_score(y_labels, preds)\n",
    "    roundedPreds = preds.round()\n",
    "    Kappa = cohen_kappa_score(y_labels,roundedPreds)\n",
    "    AdjAUC = (rocAUC - 0.5) * 2 if (rocAUC>0.5) else 0\n",
    "    AdjKappa = Kappa if (Kappa > 0) else 0\n",
    "    return 'rocAucKappa',float(1 - (AdjAUC + AdjKappa))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams.update({'font.size':12, 'figure.figsize':[10,7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing columns with less than 10 values\n",
      "Removing columns not present in both training and hidden\n"
     ]
    }
   ],
   "source": [
    "#Read in Training Feature Data\n",
    "train = pd.read_csv('../TrainingData/FullScrapeT10.csv')\n",
    "target = 'Target'\n",
    "IDcol = 'StudentID'\n",
    "train = train.drop(['StudentID'],axis=1)\n",
    "#remove duplicates\n",
    "train = train.loc[:,~train.columns.str.endswith('.1')]\n",
    "\n",
    "#Read in Hidden Feature Data\n",
    "dataPred = pd.read_csv('../TrainingData/FullScrapeH10.csv')\n",
    "idDF = pd.DataFrame(dataPred.StudentID)\n",
    "\n",
    "#Convert from boolean to binary\n",
    "train[target] *=1\n",
    "train.head()\n",
    "\n",
    "#Data Cleaning - Optional\n",
    "\n",
    "#Remove more than threshold missing values\n",
    "print(\"Removing columns with less than 10 values\")\n",
    "threshold = 10\n",
    "train = train.dropna(axis=1,thresh=threshold)\n",
    "train.head()\n",
    "\n",
    "#In case Hidden and Training have different columns\n",
    "#This is primarily for click rate for which additional columns are generated for every 10 clicks.\n",
    "print(\"Removing columns not present in both training and hidden\")\n",
    "for col in train.columns:\n",
    "    if (not col in dataPred.columns and not col==target):\n",
    "        train = train.drop(col, axis=1)\n",
    "        print(i)\n",
    "        \n",
    "#Seperate Target and Features\n",
    "X, y = train.drop([target],axis=1),train[target]\n",
    "#Sort X columns alphabetically\n",
    "X = X.reindex(sorted(X.columns), axis=1)\n",
    "\n",
    "#Split into training and validation set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
    "\n",
    "\n",
    "#XGBRegressor Model\n",
    "xg_reg = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.3min finished\n",
      "C:\\Users\\nlevi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\nlevi\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\nlevi\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5065066765220444\n",
      "{'subsample': 0.9, 'objective': 'binary:logistic', 'n_estimators': 100, 'min_child_weight': 2, 'max_depth': 3, 'learning_rate': 0.08, 'gamma': 1, 'colsample_bytree': 0.9}\n",
      "Removing columns based on feature importance\n",
      "Enter Item\n",
      "Exit Item\n",
      "Click Choice\n",
      "Open Calculator\n",
      "Move Calculator\n",
      "VH139047\n",
      "MatchMS \n",
      "Calculator Buffer\n",
      "VH098759\n",
      "Math Keypress\n",
      "Lose Focus\n",
      "NumActs\n",
      "NumQuests\n",
      "Revisits\n",
      "Click Progress Navigator\n",
      "Scratchwork Mode On\n",
      "Scratchwork Mode Off\n",
      "Scratchwork Erase Mode On\n",
      "Erase\n",
      "Scratchwork Draw Mode On\n",
      "Close Calculator\n",
      "Highlight\n",
      "VH134387\n",
      "FillInBlank\n",
      "TextToSpeech\n",
      "Clear Answer\n",
      "VH098783\n",
      "Increase Zoom\n",
      "Decrease Zoom\n",
      "Change Theme\n",
      "Back\n",
      "VH139196\n",
      "CompositeCR\n",
      "Hide Timer\n",
      "Show Timer\n",
      "BlockReview\n",
      "HELPMAT8\n",
      "Help\n",
      "VH098812\n",
      "First Text Change\n",
      "Equation Editor Button\n",
      "VH098522\n",
      "VH134373\n",
      "VH098839\n",
      "VH098597\n",
      "VH098556\n",
      "Open Equation Editor\n",
      "Close Equation Editor\n",
      "VH098779\n",
      "VH098834\n",
      "EOSTimeLft\n",
      "TimeLeftMessage\n",
      "Yes\n",
      "Leave Section\n",
      "Draw;Scratchwork Erase Mode On;Erase\n",
      "Draw;Scratchwork Erase Mode On;Erase_PT\n",
      "Scratchwork Mode Off;Vertical Item Scroll;Eliminate Choice\n",
      "Scratchwork Mode Off;Vertical Item Scroll;Eliminate Choice_PT\n",
      "Close Calculator;Open Calculator\n",
      "Close Calculator;Open Calculator_PT\n",
      "Lose Focus;Click Progress Navigator\n",
      "Lose Focus;Click Progress Navigator_PT\n",
      "Receive Focus;Equation Editor Button\n",
      "Receive Focus;Equation Editor Button_PT\n",
      "Vertical Item Scroll;Lose Focus\n",
      "Vertical Item Scroll;Open Calculator;Click Choice\n",
      "Vertical Item Scroll;Open Calculator;Click Choice_PT\n",
      "Enter Item;Open Calculator_PT\n",
      "Enter Item;Click Choice\n",
      "Enter Item;Receive Focus\n",
      "Enter Item;Receive Focus_PT\n",
      "Enter Item;Eliminate Choice\n",
      "Enter Item;Eliminate Choice_PT\n",
      "Enter Item;Next\n",
      "Enter Item;Next_PT\n",
      "Enter Item;Next_PT_R\n",
      "Enter Item;Vertical Item Scroll;Open Calculator\n",
      "Enter Item;Open Calculator;Calculator Buffer\n",
      "Enter Item;DropChoice\n",
      "Enter Item;DropChoice_PT\n",
      "Enter Item;Scratchwork Mode On\n",
      "Enter Item;Scratchwork Mode On_PT\n",
      "Enter Item;Click Progress Navigator_PT\n",
      "Enter Item;Increase Zoom\n",
      "Enter Item;Increase Zoom_PT\n",
      "Move Calculator;Exit Item\n",
      "Move Calculator;Exit Item_PT\n",
      "Move Calculator;DropChoice\n",
      "Move Calculator;DropChoice_PT\n",
      "Move Calculator;Receive Focus\n",
      "Move Calculator;Receive Focus_PT\n",
      "Move Calculator;Click Choice\n",
      "Move Calculator;Click Choice_PT_R\n",
      "Open Calculator;Click Choice\n",
      "Open Calculator;Click Choice_PT\n",
      "Receive Focus;Lose Focus\n",
      "Receive Focus;Lose Focus_PT\n",
      "Vertical Item Scroll;Open Calculator\n",
      "Vertical Item Scroll;Open Calculator_PT\n",
      "Exit Item;Enter Item;Click Choice\n",
      "Exit Item;Enter Item;Click Choice_PT_R\n",
      "Exit Item;Enter Item\n",
      "Exit Item;Enter Item;Next\n",
      "Exit Item;Enter Item;Next_PT\n",
      "Math Keypress;First Text Change\n",
      "Math Keypress;First Text Change_PT\n",
      "Draw;Draw\n",
      "Draw;Draw_PT\n",
      "Enter Item;Next;Exit Item\n",
      "Enter Item;Next;Exit Item_PT\n",
      "Enter Item;Next;Exit Item_PT_R\n",
      "Exit Item;Calculator Buffer;Close Calculator;Click Choice\n",
      "Exit Item;Calculator Buffer;Close Calculator;Click Choice_PT\n",
      "Close Calculator;Click Choice\n",
      "Exit Item;Calculator Buffer\n",
      "Enter Item;Open Calculator;Move Calculator;DropChoice\n",
      "Enter Item;Open Calculator;Move Calculator;DropChoice_PT\n",
      "Enter Item;Open Calculator;Move Calculator\n",
      "Click Choice;Next;Exit Item\n",
      "Click Choice;Next\n",
      "Click Choice;Next_PT\n",
      "Click Choice;Next_PT_R\n",
      "Enter Item;Eliminate Choice;Click Choice\n",
      "Enter Item;Eliminate Choice;Click Choice_PT\n",
      "Vertical Item Scroll;Next\n",
      "Vertical Item Scroll;Next_PT\n",
      "Move Calculator;Eliminate Choice\n",
      "Move Calculator;Eliminate Choice_PT\n",
      "Click Choice;Click Progress Navigator\n",
      "Click Choice;Click Progress Navigator_PT\n",
      "Click Progress Navigator;Exit Item\n",
      "Click Progress Navigator;Exit Item_PT\n",
      "DropChoice;DropChoice_PT\n",
      "Calculator Buffer;Enter Item\n",
      "Move Calculator;Move Calculator_PT\n",
      "Clear Answer;Click Choice\n",
      "Exit Item;Calculator Buffer;Close Calculator\n",
      "Exit Item;Calculator Buffer;Close Calculator_PT\n",
      "Receive Focus;Math Keypress;Lose Focus\n",
      "Receive Focus;Math Keypress\n",
      "Receive Focus;Math Keypress_PT\n",
      "Draw;Clear Scratchwork\n",
      "Draw;Clear Scratchwork_PT\n",
      "Lose Focus;Click Progress Navigator_PT_R\n",
      "Vertical Item Scroll;Lose Focus_PT_R\n",
      "Enter Item;Click Progress Navigator_PT_R\n",
      "Click Progress Navigator;Exit Item_PT_R\n",
      "Draw;Scratchwork Erase Mode On;Erase_PT_R\n",
      "Draw;Draw_PT_R\n",
      "Vertical Item Scroll;Next_PT_R\n",
      "Enter Item;Open Calculator;Calculator Buffer_PT_R\n",
      "Move Calculator;DropChoice_PT_R\n",
      "Receive Focus;Lose Focus_PT_R\n",
      "Receive Focus;Math Keypress;Lose Focus_PT_R\n",
      "Draw;Clear Scratchwork_PT_R\n",
      "Enter Item;Receive Focus_PT_R\n",
      "Open Calculator;Click Choice_PT_R\n",
      "Exit Item;Enter Item;Next_PT_R\n",
      "Math Keypress;First Text Change_PT_R\n",
      "Enter Item;Eliminate Choice;Click Choice_PT_R\n",
      "Receive Focus;Equation Editor Button_PT_R\n",
      "Move Calculator;Eliminate Choice_PT_R\n",
      "Move Calculator_T\n",
      "actionRate0\n",
      "Scratchwork Mode On_T\n",
      "Draw_T\n",
      "Scratchwork Erase Mode On_T\n",
      "actionRate100\n",
      "actionRate140\n",
      "actionRate150\n",
      "actionRate160\n",
      "actionRate170\n",
      "actionRate180\n",
      "actionRate200\n",
      "actionRate210\n",
      "Clear Scratchwork_T\n",
      "Increase Zoom_T\n",
      "Decrease Zoom_T\n",
      "Change Theme_T\n",
      "Back_T\n",
      "actionRate230\n",
      "actionRate240\n",
      "First Text Change_T\n",
      "Equation Editor Button_T\n",
      "Open Equation Editor_T\n",
      "Close Equation Editor_T\n",
      "actionRate260\n",
      "actionRate270\n",
      "actionRate280\n",
      "actionRate290\n",
      "actionRate300\n",
      "actionRate310\n",
      "Yes_T\n",
      "Leave Section_T\n",
      "clickRate2\n",
      "clickRate8\n",
      "DirectionsObsClicks\n",
      "VH356862QClicks\n",
      "MCSSObsClicks\n",
      "VH098810QClicks\n",
      "VH098519QClicks\n",
      "VH139047QClicks\n",
      "VH134366QClicks\n",
      "VH098753QClicks\n",
      "VH134387QClicks\n",
      "VH098783QClicks\n",
      "CompositeCRObsClicks\n",
      "VH139196QClicks\n",
      "BlockReviewObsClicks\n",
      "BlockRevQClicks\n",
      "HelpObsClicks\n",
      "HELPMAT8QClicks\n",
      "VH098522QClicks\n",
      "VH134373QClicks\n",
      "VH098839QClicks\n",
      "VH098597QClicks\n",
      "VH098556QClicks\n",
      "VH098779QClicks\n",
      "VH098834QClicks\n",
      "TimeLeftMessageObsClicks\n",
      "EOSTimeLftQClicks\n",
      "min_PT_R\n",
      "mean_PT\n",
      "min_PT\n",
      "range_PT\n",
      "maxAction\n",
      "minAction\n",
      "rangeAction\n",
      "sdCR\n",
      "maxCR\n",
      "minCR\n",
      "rangeCR\n",
      "meanQClicks\n",
      "maxQClicks\n",
      "minQClicks\n",
      "rangeQClicks\n",
      "meanObsClicks\n",
      "rangeObsClicks\n",
      "Number of Features Remaining:  127\n",
      "Number of Features Remaining:  127\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.2min finished\n",
      "C:\\Users\\nlevi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.584989850357765\n",
      "{'subsample': 0.9, 'objective': 'binary:logistic', 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 4, 'learning_rate': 0.08, 'gamma': 2, 'colsample_bytree': 0.2}\n",
      "Removing columns based on feature importance\n",
      "DropChoice\n",
      "Clear Scratchwork\n",
      "BlockRev\n",
      "Vertical Item Scroll;Lose Focus_PT\n",
      "Enter Item;Open Calculator\n",
      "Enter Item;Eliminate Choice_PT_R\n",
      "Enter Item;Vertical Item Scroll;Open Calculator_PT\n",
      "Enter Item;Open Calculator;Calculator Buffer_PT\n",
      "Exit Item;Enter Item_PT\n",
      "Close Calculator;Click Choice_PT\n",
      "Click Choice;Next;Exit Item_PT\n",
      "DropChoice;DropChoice\n",
      "Calculator Buffer;Enter Item_PT\n",
      "Move Calculator;Move Calculator\n",
      "Move Calculator;Move Calculator_PT_R\n",
      "Clear Answer;Click Choice_PT\n",
      "Receive Focus;Math Keypress;Lose Focus_PT\n",
      "Receive Focus;Math Keypress_PT_R\n",
      "Clear Answer;Click Choice_PT_R\n",
      "DropChoice_T\n",
      "Click Progress Navigator_T\n",
      "Erase_T\n",
      "actionRate120\n",
      "actionRate130\n",
      "actionRate190\n",
      "actionRate220\n",
      "TextToSpeech_T\n",
      "Clear Answer_T\n",
      "Hide Timer_T\n",
      "actionRate250\n",
      "clickRate0\n",
      "clickRate5\n",
      "VH098808QClicks\n",
      "MatchMS ObsClicks\n",
      "MultipleFillInBlankObsClicks\n",
      "mean_PT_R\n",
      "sdQClicks\n",
      "minObsClicks\n",
      "Number of Features Remaining:  89\n",
      "Number of Features Remaining:  89\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.0min finished\n",
      "C:\\Users\\nlevi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5711777645122939\n",
      "{'subsample': 1.0, 'objective': 'binary:logistic', 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 4, 'learning_rate': 0.06000000000000001, 'gamma': 2, 'colsample_bytree': 1.0}\n",
      "Removing columns based on feature importance\n",
      "VH134366\n",
      "Vertical Item Scroll\n",
      "Receive Focus\n",
      "Draw\n",
      "Scratchwork Highlight Mode On\n",
      "Enter Item;Click Choice_PT\n",
      "Exit Item;Enter Item;Click Choice_PT\n",
      "Enter Item;Open Calculator;Move Calculator_PT\n",
      "Click Choice;Next;Exit Item_PT_R\n",
      "Click Choice;Click Progress Navigator_PT_R\n",
      "Enter Item;Vertical Item Scroll;Open Calculator_PT_R\n",
      "Vertical Item Scroll;Open Calculator_PT_R\n",
      "StartTime\n",
      "actionRate20\n",
      "actionRate30\n",
      "Scratchwork Mode Off_T\n",
      "Scratchwork Draw Mode On_T\n",
      "Highlight_T\n",
      "clickRate4\n",
      "VH098740QClicks\n",
      "sd_PT\n",
      "max_PT\n",
      "meanCR\n",
      "meanQ\n",
      "rangeQ\n",
      "Number of Features Remaining:  64\n",
      "Number of Features Remaining:  64\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.7s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "scorer = make_scorer(scoreFunc)\n",
    "#kfold = StratifiedKFold(10,shuffle=True,random_state=1988)\n",
    "parameters = {\n",
    "    'objective':['binary:logistic'],\n",
    "    'learning_rate':np.linspace(.01,.1,num=10,endpoint=True),\n",
    "    'max_depth': range(3,8,1),\n",
    "    'min_child_weight': range(1,7,1),\n",
    "    'subsample': np.linspace(.1,1.0,num=10,endpoint=True),\n",
    "    'colsample_bytree': np.linspace(.1,1.0,num=10,endpoint=True),\n",
    "    'gamma':range(0,5,1),\n",
    "    'n_estimators': [100]}\n",
    "\n",
    "while(len(X.columns) > 30):\n",
    "    xgb_grid = RandomizedSearchCV(xg_reg,  parameters,n_iter=20,n_jobs = -1,scoring=scorer, cv=10, verbose=True)\n",
    "\n",
    "    xgb_grid.fit(X, y)\n",
    "\n",
    "    best_model = xgb_grid.best_estimator_\n",
    "\n",
    "    print(xgb_grid.best_score_)\n",
    "    print(xgb_grid.best_params_)\n",
    "    \n",
    "    #Calculate important features based on number of trees in which they occur\n",
    "    featImportArr = best_model.feature_importances_\n",
    "    fScores = best_model.get_booster().get_fscore()\n",
    "    fScores = fScores.items()\n",
    "    fScores = sorted(fScores, key=lambda x: x[1])\n",
    "    fScores = fScores[int(len(fScores)*0.25):]\n",
    "    keptFeatures = [i[0] for i in fScores]\n",
    "\n",
    "    #Only keep top 75% of features\n",
    "    print(\"Removing columns based on feature importance\")\n",
    "    for col in train.columns:\n",
    "        if (not col in keptFeatures and not col==target):\n",
    "            train = train.drop(col, axis=1)\n",
    "            print(col)\n",
    "\n",
    "    #Seperate Target and Features\n",
    "    X, y = train.drop([target],axis=1),train[target]\n",
    "    print(\"Number of Features Remaining: \", len(X.columns))\n",
    "    #Sort X columns alphabetically\n",
    "    X = X.reindex(sorted(X.columns), axis=1)\n",
    "    print(\"Number of Features Remaining: \", len(X.columns))\n",
    "\n",
    "    #XGBRegressor Model\n",
    "    xg_reg = xgb.XGBRegressor()\n",
    "    \n",
    "xgb_grid = RandomizedSearchCV(xg_reg,  parameters,n_iter=200,n_jobs = -1,scoring=scorer, cv=10, verbose=True)\n",
    "\n",
    "xgb_grid.fit(X, y)\n",
    "\n",
    "best_model = xgb_grid.best_estimator_\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training score\n",
    "Xpredictions = best_model.predict(X)\n",
    "scoreFunc(y,Xpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Hyper-parameters and Validation Score\n",
    "#0.6442671192414215\n",
    "#{'subsample': 0.9, 'objective': 'binary:logistic', 'n_estimators': 90, \n",
    "# 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.07, 'gamma': 0, 'colsample_bytree': 0.8}\n",
    "\n",
    "#OPTIONAL- Use Grid Search for more comprehensive hyperparameter tuning\n",
    "#from sklearn.metrics import make_scorer\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#scorer = make_scorer(scoreFunc)\n",
    "#kfold = StratifiedKFold(10,shuffle=True,random_state=1988)\n",
    "#parameters = {\n",
    "#    'objective':['binary:logistic'],\n",
    "#    'learning_rate':[.03],\n",
    "#    'max_depth': [8],\n",
    "#    'min_child_weight': [3],\n",
    "#    'subsample': [0.7],\n",
    "#    'colsample_bytree': [0.4],\n",
    "#    'gamma':[6],\n",
    "#    'n_estimators': range(190,210,2)}\n",
    "\n",
    "#xgb_grid = GridSearchCV(xg_reg,  parameters,n_jobs = -1,scoring=scorer, cv=3, verbose=True)\n",
    "\n",
    "#xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "#print(xgb_grid.best_score_)\n",
    "#print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(best_model,max_num_features=10, title = \"Feature Importance 10 Minute Model\")\n",
    "plt.rcParams['figure.figsize'] = [10, 7]\n",
    "plt.savefig('FeatImport_10.png')\n",
    "\n",
    "\n",
    "for col in dataPred.columns:\n",
    "    if (not col in train.columns):\n",
    "        dataPred = dataPred.drop(col, axis=1)\n",
    "        \n",
    "#dataPred= dataPred.drop('Target',axis=1)\n",
    "dataPred = dataPred.reindex(sorted(dataPred.columns), axis=1)\n",
    "print(dataPred.head())\n",
    "\n",
    "preds = best_model.predict(dataPred)\n",
    "\n",
    "predDF = pd.DataFrame(preds,columns=['Target'])\n",
    "predDF.head()\n",
    "output = pd.concat([idDF,predDF], axis = 1)\n",
    "output.head()\n",
    "\n",
    "output.to_csv('hidden10_Output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 Minute Model\n",
    "#Read in Training Feature Data\n",
    "train = pd.read_csv('../TrainingData/FullScrapeT20.csv')\n",
    "target = 'Target'\n",
    "IDcol = 'StudentID'\n",
    "train = train.drop(['StudentID'],axis=1)\n",
    "#remove duplicates\n",
    "train = train.loc[:,~train.columns.str.endswith('.1')]\n",
    "\n",
    "#Read in Hidden Feature Data\n",
    "dataPred = pd.read_csv('../TrainingData/FullScrapeH20.csv')\n",
    "idDF = pd.DataFrame(dataPred.StudentID)\n",
    "\n",
    "#Convert from boolean to binary\n",
    "train[target] *=1\n",
    "train.head()\n",
    "\n",
    "#Data Cleaning - Optional\n",
    "\n",
    "#Remove more than threshold missing values\n",
    "print(\"Removing columns with less than 10 values\")\n",
    "threshold = 10\n",
    "train = train.dropna(axis=1,thresh=threshold)\n",
    "train.head()\n",
    "\n",
    "#In case Hidden and Training have different columns\n",
    "#This is primarily for click rate for which additional columns are generated for every 10 clicks.\n",
    "print(\"Removing columns not present in both training and hidden\")\n",
    "for col in train.columns:\n",
    "    if (not col in dataPred.columns and not col==target):\n",
    "        train = train.drop(col, axis=1)\n",
    "        print(i)\n",
    "        \n",
    "#Seperate Target and Features\n",
    "X, y = train.drop([target],axis=1),train[target]\n",
    "#Sort X columns alphabetically\n",
    "X = X.reindex(sorted(X.columns), axis=1)\n",
    "\n",
    "#Split into training and validation set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
    "\n",
    "#XGBRegressor Model\n",
    "xg_reg = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "scorer = make_scorer(scoreFunc)\n",
    "#kfold = StratifiedKFold(10,shuffle=True,random_state=1988)\n",
    "parameters = {\n",
    "    'objective':['binary:logistic'],\n",
    "    'learning_rate':np.linspace(.01,.1,num=10,endpoint=True),\n",
    "    'max_depth': range(3,8,1),\n",
    "    'min_child_weight': range(1,7,1),\n",
    "    'subsample': np.linspace(.1,1.0,num=10,endpoint=True),\n",
    "    'colsample_bytree': np.linspace(.1,1.0,num=10,endpoint=True),\n",
    "    'gamma':range(0,5,1),\n",
    "    'n_estimators': [100]}\n",
    "\n",
    "while(len(X.columns) > 30):\n",
    "    xgb_grid = RandomizedSearchCV(xg_reg,  parameters,n_iter=20,n_jobs = -1,scoring=scorer, cv=10, verbose=True)\n",
    "\n",
    "    xgb_grid.fit(X, y)\n",
    "\n",
    "    best_model = xgb_grid.best_estimator_\n",
    "\n",
    "    print(xgb_grid.best_score_)\n",
    "    print(xgb_grid.best_params_)\n",
    "    \n",
    "    #Calculate important features based on number of trees in which they occur\n",
    "    featImportArr = best_model.feature_importances_\n",
    "    fScores = best_model.get_booster().get_fscore()\n",
    "    fScores = fScores.items()\n",
    "    fScores = sorted(fScores, key=lambda x: x[1])\n",
    "    fScores = fScores[int(len(fScores)*0.25):]\n",
    "    keptFeatures = [i[0] for i in fScores]\n",
    "\n",
    "    #Only keep top 75% of features\n",
    "    print(\"Removing columns based on feature importance\")\n",
    "    for col in train.columns:\n",
    "        if (not col in keptFeatures and not col==target):\n",
    "            train = train.drop(col, axis=1)\n",
    "            print(col)\n",
    "\n",
    "    #Seperate Target and Features\n",
    "    X, y = train.drop([target],axis=1),train[target]\n",
    "    print(\"Number of Features Remaining: \", len(X.columns))\n",
    "    #Sort X columns alphabetically\n",
    "    X = X.reindex(sorted(X.columns), axis=1)\n",
    "    print(\"Number of Features Remaining: \", len(X.columns))\n",
    "\n",
    "    #XGBRegressor Model\n",
    "    xg_reg = xgb.XGBRegressor()\n",
    "    \n",
    "xgb_grid = RandomizedSearchCV(xg_reg,  parameters,n_iter=200,n_jobs = -1,scoring=scorer, cv=10, verbose=True)\n",
    "\n",
    "xgb_grid.fit(X, y)\n",
    "\n",
    "best_model = xgb_grid.best_estimator_\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training score\n",
    "Xpredictions = best_model.predict(X)\n",
    "scoreFunc(y,Xpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Hyper-parameters and Validation Score\n",
    "#0.7593081688312175\n",
    "#{'subsample': 1.0, 'objective': 'binary:logistic', 'n_estimators': 70, 'min_child_weight': 3,\n",
    "# 'max_depth': 4, 'learning_rate': 0.05000000000000001, 'gamma': 3, 'colsample_bytree': 0.30000000000000004}\n",
    "\n",
    "#OPTIONAL- Use Grid Search for more comprehensive hyperparameter tuning\n",
    "#from sklearn.metrics import make_scorer\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#scorer = make_scorer(scoreFunc)\n",
    "#kfold = StratifiedKFold(10,shuffle=True,random_state=1988)\n",
    "#parameters = {\n",
    "#    'objective':['binary:logistic'],\n",
    "#    'learning_rate':[.03],\n",
    "#    'max_depth': [8],\n",
    "#    'min_child_weight': [3],\n",
    "#    'subsample': [0.7],\n",
    "#    'colsample_bytree': [0.4],\n",
    "#    'gamma':[6],\n",
    "#    'n_estimators': range(190,210,2)}\n",
    "\n",
    "#xgb_grid = GridSearchCV(xg_reg,  parameters,n_jobs = -1,scoring=scorer, cv=3, verbose=True)\n",
    "\n",
    "#xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "#print(xgb_grid.best_score_)\n",
    "#print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(best_model,max_num_features=10, title=\"Feature Importance 20 Minute Model\")\n",
    "plt.savefig('FeatImport_20.png')\n",
    "\n",
    "\n",
    "for col in dataPred.columns:\n",
    "    if (not col in train.columns):\n",
    "        dataPred = dataPred.drop(col, axis=1)\n",
    "        \n",
    "#dataPred= dataPred.drop('Target',axis=1)\n",
    "dataPred = dataPred.reindex(sorted(dataPred.columns), axis=1)\n",
    "print(dataPred.head())\n",
    "\n",
    "preds = best_model.predict(dataPred)\n",
    "\n",
    "predDF = pd.DataFrame(preds,columns=['Target'])\n",
    "predDF.head()\n",
    "output = pd.concat([idDF,predDF], axis = 1)\n",
    "output.head()\n",
    "\n",
    "output.to_csv('hidden20_Output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30 Minute Model\n",
    "#Read in Training Feature Data\n",
    "train = pd.read_csv('../TrainingData/FullScrapeT30.csv')\n",
    "target = 'Target'\n",
    "IDcol = 'StudentID'\n",
    "train = train.drop(['StudentID'],axis=1)\n",
    "#remove duplicates\n",
    "train = train.loc[:,~train.columns.str.endswith('.1')]\n",
    "\n",
    "#Read in Hidden Feature Data\n",
    "dataPred = pd.read_csv('../TrainingData/FullScrapeH30.csv')\n",
    "idDF = pd.DataFrame(dataPred.StudentID)\n",
    "\n",
    "\n",
    "#Convert from boolean to binary\n",
    "train[target] *=1\n",
    "train.head()\n",
    "\n",
    "#Data Cleaning - Optional\n",
    "\n",
    "#Remove more than threshold missing values\n",
    "print(\"Removing columns with less than 10 values\")\n",
    "threshold = 10\n",
    "train = train.dropna(axis=1,thresh=threshold)\n",
    "train.head()\n",
    "\n",
    "#In case Hidden and Training have different columns\n",
    "#This is primarily for click rate for which additional columns are generated for every 10 clicks.\n",
    "print(\"Removing columns not present in both training and hidden\")\n",
    "for col in train.columns:\n",
    "    if (not col in dataPred.columns and not col==target):\n",
    "        train = train.drop(col, axis=1)\n",
    "        print(i)\n",
    "        \n",
    "#Seperate Target and Features\n",
    "X, y = train.drop([target],axis=1),train[target]\n",
    "#Sort X columns alphabetically\n",
    "X = X.reindex(sorted(X.columns), axis=1)\n",
    "\n",
    "#Split into training and validation set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
    "\n",
    "#XGBRegressor Model\n",
    "xg_reg = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "scorer = make_scorer(scoreFunc)\n",
    "#kfold = StratifiedKFold(10,shuffle=True,random_state=1988)\n",
    "parameters = {\n",
    "    'objective':['binary:logistic'],\n",
    "    'learning_rate':np.linspace(.01,.1,num=10,endpoint=True),\n",
    "    'max_depth': range(3,8,1),\n",
    "    'min_child_weight': range(1,7,1),\n",
    "    'subsample': np.linspace(.1,1.0,num=10,endpoint=True),\n",
    "    'colsample_bytree': np.linspace(.1,1.0,num=10,endpoint=True),\n",
    "    'gamma':range(0,5,1),\n",
    "    'n_estimators': [100]}\n",
    "\n",
    "while(len(X.columns) > 30):\n",
    "    xgb_grid = RandomizedSearchCV(xg_reg,  parameters,n_iter=20,n_jobs = -1,scoring=scorer, cv=10, verbose=True)\n",
    "\n",
    "    xgb_grid.fit(X, y)\n",
    "\n",
    "    best_model = xgb_grid.best_estimator_\n",
    "\n",
    "    print(xgb_grid.best_score_)\n",
    "    print(xgb_grid.best_params_)\n",
    "    \n",
    "    #Calculate important features based on number of trees in which they occur\n",
    "    featImportArr = best_model.feature_importances_\n",
    "    fScores = best_model.get_booster().get_fscore()\n",
    "    fScores = fScores.items()\n",
    "    fScores = sorted(fScores, key=lambda x: x[1])\n",
    "    fScores = fScores[int(len(fScores)*0.25):]\n",
    "    keptFeatures = [i[0] for i in fScores]\n",
    "\n",
    "    #Only keep top 75% of features\n",
    "    print(\"Removing columns based on feature importance\")\n",
    "    for col in train.columns:\n",
    "        if (not col in keptFeatures and not col==target):\n",
    "            train = train.drop(col, axis=1)\n",
    "            print(col)\n",
    "\n",
    "    #Seperate Target and Features\n",
    "    X, y = train.drop([target],axis=1),train[target]\n",
    "    print(\"Number of Features Remaining: \", len(X.columns))\n",
    "    #Sort X columns alphabetically\n",
    "    X = X.reindex(sorted(X.columns), axis=1)\n",
    "    print(\"Number of Features Remaining: \", len(X.columns))\n",
    "\n",
    "    #XGBRegressor Model\n",
    "    xg_reg = xgb.XGBRegressor()\n",
    "    \n",
    "xgb_grid = RandomizedSearchCV(xg_reg,  parameters,n_iter=200,n_jobs = -1,scoring=scorer, cv=10, verbose=True)\n",
    "\n",
    "xgb_grid.fit(X, y)\n",
    "\n",
    "best_model = xgb_grid.best_estimator_\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training score\n",
    "Xpredictions = best_model.predict(X)\n",
    "scoreFunc(y,Xpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Hyper-parameters and Validation Score\n",
    "#0.7842701038048573\n",
    "#{'subsample': 0.6, 'objective': 'binary:logistic', 'n_estimators': 90, 'min_child_weight': 5,\n",
    "# 'max_depth': 3, 'learning_rate': 0.06000000000000001, 'gamma': 2, 'colsample_bytree': 0.30000000000000004}\n",
    "\n",
    "#OPTIONAL- Use Grid Search for more comprehensive hyperparameter tuning\n",
    "#from sklearn.metrics import make_scorer\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#scorer = make_scorer(scoreFunc)\n",
    "#kfold = StratifiedKFold(10,shuffle=True,random_state=1988)\n",
    "#parameters = {\n",
    "#    'objective':['binary:logistic'],\n",
    "#    'learning_rate':[.03],\n",
    "#    'max_depth': [8],\n",
    "#    'min_child_weight': [3],\n",
    "#    'subsample': [0.7],\n",
    "#    'colsample_bytree': [0.4],\n",
    "#    'gamma':[6],\n",
    "#    'n_estimators': range(190,210,2)}\n",
    "\n",
    "#xgb_grid = GridSearchCV(xg_reg,  parameters,n_jobs = -1,scoring=scorer, cv=3, verbose=True)\n",
    "\n",
    "#xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "#print(xgb_grid.best_score_)\n",
    "#print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(best_model,max_num_features=10,title = \"Feature Importance 30 Minute Model\")\n",
    "plt.rcParams['figure.figsize'] = [10, 7]\n",
    "plt.savefig('FeatImport_30.png')\n",
    "\n",
    "\n",
    "for col in dataPred.columns:\n",
    "    if (not col in train.columns):\n",
    "        dataPred = dataPred.drop(col, axis=1)\n",
    "        \n",
    "#dataPred= dataPred.drop('Target',axis=1)\n",
    "dataPred = dataPred.reindex(sorted(dataPred.columns), axis=1)\n",
    "print(dataPred.head())\n",
    "\n",
    "preds = best_model.predict(dataPred)\n",
    "\n",
    "predDF = pd.DataFrame(preds,columns=['Target'])\n",
    "predDF.head()\n",
    "output = pd.concat([idDF,predDF], axis = 1)\n",
    "output.head()\n",
    "\n",
    "output.to_csv('hidden30_Output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in predictions and combine them\n",
    "hidden10 = pd.read_csv('hidden10_Output.csv')\n",
    "hidden20 = pd.read_csv('hidden20_Output.csv')\n",
    "hidden30 = pd.read_csv('hidden30_Output.csv')\n",
    "frames = [hidden10,hidden20,hidden30]\n",
    "result = pd.concat(frames)\n",
    "\n",
    "#Sort by StudentID to match test\n",
    "hidden10 = hidden10.sort_values(by='StudentID')\n",
    "hidden20 = hidden20.sort_values(by='StudentID')\n",
    "hidden30 = hidden30.sort_values(by='StudentID')\n",
    "result = result.sort_values(by=['StudentID'])\n",
    "\n",
    "\n",
    "list_10_ids = hidden10['StudentID'].to_list()\n",
    "list_20_ids = hidden20['StudentID'].to_list()\n",
    "list_30_ids = hidden30['StudentID'].to_list()\n",
    "\n",
    "################################################################################################################################\n",
    "#Public Leaderboard Scoring\n",
    "\n",
    "#Read in public leaderboard test\n",
    "publicTargets = pd.read_csv('../EvaluationData/hidden_leaderboard.csv')\n",
    "\n",
    "#filter for public leaderboard ids\n",
    "list_of_ids = publicTargets['STUDENTID'].to_list()\n",
    "\n",
    "public10Preds = hidden10[hidden10.StudentID.isin(list_of_ids)]\n",
    "public10Targets = publicTargets[publicTargets.STUDENTID.isin(list_10_ids)]\n",
    "\n",
    "public20Preds = hidden20[hidden20.StudentID.isin(list_of_ids)]\n",
    "public20Targets = publicTargets[publicTargets.STUDENTID.isin(list_20_ids)]\n",
    "\n",
    "public30Preds = hidden30[hidden30.StudentID.isin(list_of_ids)]\n",
    "public30Targets = publicTargets[publicTargets.STUDENTID.isin(list_30_ids)]\n",
    "\n",
    "publicPreds = result[result.StudentID.isin(list_of_ids)]\n",
    "\n",
    "#Extract just the target values for scoring\n",
    "publicPredsArr = publicPreds.loc[:,'Target']\n",
    "publicTarArr = publicTargets.loc[:,'EfficientlyCompletedBlockB']\n",
    "public10PredsArr = public10Preds.loc[:,'Target']\n",
    "public10TarArr = public10Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "public20PredsArr = public20Preds.loc[:,'Target']\n",
    "public20TarArr = public20Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "public30PredsArr = public30Preds.loc[:,'Target']\n",
    "public30TarArr = public30Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "\n",
    "print(\"Scoring on Public Leaderboard 10: \\n\")\n",
    "leaderBoard = scoreFunc(public10TarArr, public10PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nScoring on Public Leaderboard 20: \\n\")\n",
    "leaderBoard = scoreFunc(public20TarArr, public20PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nScoring on Public Leaderboard 30: \\n\")\n",
    "leaderBoard = scoreFunc(public30TarArr, public30PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nTotal Scoring on Public Leaderboard: \\n\")\n",
    "hiddenLeaderBoard = scoreFunc(publicTarArr,publicPredsArr)\n",
    "print(\"\\nTotal: \", hiddenLeaderBoard)\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "#Final Leaderboard Scoring\n",
    "finalTargets = pd.read_csv('../EvaluationData/hidden_test.csv')\n",
    "\n",
    "\n",
    "#filter for final leaderboard ids\n",
    "list_of_ids = finalTargets['STUDENTID'].to_list()\n",
    "\n",
    "\n",
    "final10Preds = hidden10[hidden10.StudentID.isin(list_of_ids)]\n",
    "final10Targets = finalTargets[finalTargets.STUDENTID.isin(list_10_ids)]\n",
    "\n",
    "final20Preds = hidden20[hidden20.StudentID.isin(list_of_ids)]\n",
    "final20Targets = finalTargets[finalTargets.STUDENTID.isin(list_20_ids)]\n",
    "\n",
    "final30Preds = hidden30[hidden30.StudentID.isin(list_of_ids)]\n",
    "final30Targets = finalTargets[finalTargets.STUDENTID.isin(list_30_ids)]\n",
    "\n",
    "finalPreds = result[result.StudentID.isin(list_of_ids)]\n",
    "\n",
    "#Extract just the target values for scoring\n",
    "final10PredsArr = final10Preds.loc[:,'Target']\n",
    "final10TarArr = final10Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "final20PredsArr = final20Preds.loc[:,'Target']\n",
    "final20TarArr = final20Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "final30PredsArr = final30Preds.loc[:,'Target']\n",
    "final30TarArr = final30Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "finalPredsArr = finalPreds.loc[:,'Target']\n",
    "finalTarArr = finalTargets.loc[:,'EfficientlyCompletedBlockB']\n",
    "\n",
    "print(\"\\nScoring on final Leaderboard 10: \\n\")\n",
    "leaderBoard = scoreFunc(final10TarArr, final10PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nScoring on final Leaderboard 20: \\n\")\n",
    "leaderBoard = scoreFunc(final20TarArr, final20PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nScoring on final Leaderboard 30: \\n\")\n",
    "leaderBoard = scoreFunc(final30TarArr, final30PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nTotal Scoring on final Leaderboard: \\n\")\n",
    "finalLeaderBoard = scoreFunc(finalTarArr, finalPredsArr)\n",
    "print(\"Total: \", finalLeaderBoard)\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "#Final Leaderboard Scoring\n",
    "combinedTargets = pd.concat([finalTargets,publicTargets])\n",
    "\n",
    "#Sort by Student ID to ensure same order\n",
    "combinedTargets = combinedTargets.sort_values(by='STUDENTID')\n",
    "result = result.sort_values(by='StudentID')\n",
    "\n",
    "combined10Targets = combinedTargets[combinedTargets.STUDENTID.isin(list_10_ids)]\n",
    "\n",
    "combined20Targets = combinedTargets[combinedTargets.STUDENTID.isin(list_20_ids)]\n",
    "\n",
    "combined30Targets = combinedTargets[combinedTargets.STUDENTID.isin(list_30_ids)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Extract just the target values for scoring\n",
    "combined10PredsArr = hidden10.loc[:,'Target']\n",
    "final10TarArr = combined10Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "combined20PredsArr = hidden20.loc[:,'Target']\n",
    "final20TarArr = combined20Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "combined30PredsArr = hidden30.loc[:,'Target']\n",
    "final30TarArr = combined30Targets.loc[:,'EfficientlyCompletedBlockB']\n",
    "\n",
    "resultPreds = result.loc[:,'Target']\n",
    "publicTarArr = combinedTargets.loc[:,'EfficientlyCompletedBlockB']\n",
    "\n",
    "print(\"\\nScoring on Combined Leaderboard 10: \\n\")\n",
    "leaderBoard = scoreFunc(final10TarArr, combined10PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nScoring on Combined Leaderboard 20: \\n\")\n",
    "leaderBoard = scoreFunc(final20TarArr, combined20PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nScoring on Combined Leaderboard 30: \\n\")\n",
    "leaderBoard = scoreFunc(final30TarArr, combined30PredsArr)\n",
    "print(\"Total: \", leaderBoard)\n",
    "\n",
    "print(\"\\nTotal Combined Scoring: \\n\")\n",
    "combinedLeaderBoard = scoreFunc(publicTarArr, resultPreds)\n",
    "print(\"Total: \", combinedLeaderBoard)\n",
    "\n",
    "print(\"\\nCombined Leaderboards: \", (finalLeaderBoard + hiddenLeaderBoard)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
